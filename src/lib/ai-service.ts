import { supabase } from './supabase'

export interface AnalysisResult {
  summary: string
  insights: string[]
  trends: string[]
  impact: string
  recommendations: string[]
  keyEntities: string[]
}

export interface DailyDigest {
  sourceId: string
  date: string
  summaryMd: string
  insightsMd: string
  items: Array<{
    id: string
    title: string
    url: string
    published_at: string
    content: string
    author: string
  }>
}

export class AIService {
  // ä½¿ç”¨ OpenAI API è¿›è¡Œåˆ†æ
  static async analyzeContent(items: Array<{
    title: string
    content: string
    url: string
    published_at: string
    author: string
  }>, sourceName: string, aiFocus?: string): Promise<AnalysisResult> {
    try {
      // æ„å»ºç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
      const systemPrompt = this.buildSystemPrompt(sourceName, aiFocus)
      const userPrompt = this.buildUserPrompt(items)
      
      // è°ƒç”¨ OpenAI API
      const response = await fetch('/api/analyze', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          systemPrompt,
          userPrompt,
          items: items.slice(0, 10) // é™åˆ¶é¡¹ç›®æ•°é‡
        })
      })
      
      if (!response.ok) {
        throw new Error(`Analysis API error: ${response.status}`)
      }
      
      const result = await response.json()
      return result
      
    } catch (error) {
      console.error('AI analysis error:', error)
      // è¿”å›é»˜è®¤åˆ†æç»“æœ
      return this.getDefaultAnalysis(items, sourceName)
    }
  }
  
  // æ„å»ºç³»ç»Ÿæç¤ºè¯
  private static buildSystemPrompt(sourceName: string, aiFocus?: string): string {
    const basePrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆï¼Œä¸“é—¨åˆ†ææ¥è‡ª "${sourceName}" çš„å†…å®¹ã€‚`
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯ GitHub README æº
    if (sourceName.includes('README') || sourceName.includes('github')) {
      return `${basePrompt}

**ä¸“é—¨åˆ†æ GitHub README æ›´æ–°ï¼š**
ä½ æ­£åœ¨åˆ†æä¸€ä¸ª GitHub ä»“åº“çš„ README æ–‡ä»¶å†…å®¹ã€‚è¯·é‡ç‚¹å…³æ³¨ï¼š

1. **æœ€æ–°æ›´æ–°å†…å®¹**ï¼šè¯†åˆ« README ä¸­æ ‡æ³¨çš„æœ€æ–°è®ºæ–‡ã€æ›´æ–°æ—¥æœŸ
2. **è®ºæ–‡åˆ—è¡¨åˆ†æ**ï¼šåˆ†ææ–°å¢çš„è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨æœŸåˆŠ
3. **æŠ€æœ¯è¶‹åŠ¿**ï¼šä»è®ºæ–‡æ ‡é¢˜å’Œæè¿°ä¸­è¯†åˆ«æŠ€æœ¯å‘å±•æ–¹å‘
4. **é‡è¦å‘ç°**ï¼šæå–å…³é”®çš„æŠ€æœ¯çªç ´å’Œç ”ç©¶è¿›å±•
5. **æ›´æ–°è§£è¯»**ï¼šæ€»ç»“æœ€è¿‘æœ‰ä»€ä¹ˆé‡è¦æ›´æ–°

è¯·ç”¨ç®€æ´æ˜äº†çš„æ–¹å¼è§£è¯»æœ€æ–°æ›´æ–°ï¼Œé‡ç‚¹å…³æ³¨å˜åŒ–å’Œæ–°å¢å†…å®¹ã€‚`
    }
    
    const focusPrompt = aiFocus ? 
      `\n\n**åˆ†æé‡ç‚¹å’Œæ–¹å‘ï¼š**\n${aiFocus}\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šé‡ç‚¹è¿›è¡Œé’ˆå¯¹æ€§åˆ†æï¼Œé‡ç‚¹å…³æ³¨ç›¸å…³å†…å®¹ã€‚` : 
      `\n\nè¯·è¿›è¡Œå…¨é¢çš„å†…å®¹åˆ†æã€‚`
    
    return basePrompt + focusPrompt
  }

  // æ„å»ºç”¨æˆ·æç¤ºè¯
  private static buildUserPrompt(items: Array<{
    title: string
    content: string
    url: string
  }>): string {
    // æ£€æŸ¥æ˜¯å¦æ˜¯ GitHub README å†…å®¹
    const isGitHubReadme = items.some(item => 
      item.title.includes('README') || 
      item.content.includes('Papers last week') ||
      item.content.includes('## ') ||
      item.content.includes('### ')
    )
    
    if (isGitHubReadme) {
      const readmeContent = items[0]?.content || ''
      
      return `è¯·åˆ†æä»¥ä¸‹ GitHub README å†…å®¹ï¼š

**README å†…å®¹ï¼š**
${readmeContent.substring(0, 2000)}...

**è¯·é‡ç‚¹åˆ†æï¼š**

1. **æœ€æ–°æ›´æ–°** (100-150å­—): è¯†åˆ«å¹¶æ€»ç»“ README ä¸­æ ‡æ³¨çš„æœ€æ–°è®ºæ–‡å’Œæ›´æ–°å†…å®¹
2. **æ–°å¢è®ºæ–‡** (3-5æ¡): åˆ—å‡ºæœ€æ–°æ·»åŠ çš„è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨ä¿¡æ¯
3. **æŠ€æœ¯è¶‹åŠ¿**: ä»è®ºæ–‡æ ‡é¢˜ä¸­åˆ†æå½“å‰çš„æŠ€æœ¯å‘å±•æ–¹å‘
4. **é‡è¦çªç ´**: è¯†åˆ«é‡è¦çš„æŠ€æœ¯çªç ´å’Œç ”ç©¶è¿›å±•
5. **æ›´æ–°è§£è¯»**: ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“æœ€è¿‘æœ‰ä»€ä¹ˆé‡è¦æ›´æ–°

è¯·é‡ç‚¹å…³æ³¨å˜åŒ–å’Œæ–°å¢å†…å®¹ï¼Œç”¨ä¸­æ–‡å›ç­”ã€‚`
    }
    
    // åŸæœ‰çš„é€šç”¨åˆ†æé€»è¾‘
    const itemsText = items.map((item, index) => 
      `${index + 1}. ${item.title}\n   ${item.content?.substring(0, 200)}...\n   URL: ${item.url}\n`
    ).join('\n')
    
    return `è¯·åˆ†æä»¥ä¸‹æœ€æ–°å†…å®¹ï¼š

${itemsText}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š

1. **æ‘˜è¦** (100-150å­—): æ€»ç»“ä»Šæ—¥çš„ä¸»è¦å†…å®¹å’Œè¶‹åŠ¿
2. **å…³é”®æ´å¯Ÿ** (3-5æ¡): é‡è¦çš„å‘ç°å’Œè¶‹åŠ¿
3. **å½±å“è¯„ä¼°**: è¿™äº›å†…å®¹å¯¹ç›¸å…³é¢†åŸŸçš„å½±å“
4. **è¡ŒåŠ¨å»ºè®®** (3æ¡): åŸºäºåˆ†æçš„å…·ä½“å»ºè®®
5. **å…³é”®å®ä½“**: æåˆ°çš„é‡è¦äººç‰©ã€ç»„ç»‡æˆ–é¡¹ç›®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šå’Œå®¢è§‚ã€‚`
  }
  
  // ç”Ÿæˆæ¯æ—¥æ‘˜è¦
  static async generateDailyDigest(sourceId: string, date: string): Promise<DailyDigest> {
    try {
      // è·å–æŒ‡å®šæ—¥æœŸçš„é¡¹ç›®
      const { data: items, error: itemsError } = await supabase
        .from('items')
        .select('*')
        .eq('source_id', sourceId)
        .gte('published_at', `${date}T00:00:00Z`)
        .lt('published_at', `${date}T23:59:59Z`)
        .order('published_at', { ascending: false })
      
      if (itemsError) {
        throw new Error(`Failed to fetch items: ${itemsError.message}`)
      }
      
      if (!items || items.length === 0) {
        return {
          sourceId,
          date,
          summaryMd: 'ä»Šæ—¥æ— æ–°å†…å®¹',
          insightsMd: 'æš‚æ— æ´å¯Ÿ',
          items: []
        }
      }
      
      // è·å–æºä¿¡æ¯
      const { data: source } = await supabase
        .from('sources')
        .select('name, ai_focus')
        .eq('id', sourceId)
        .single()
      
      // è¿›è¡Œ AI åˆ†æ
      const analysis = await this.analyzeContent(items, source?.name || 'Unknown Source', source?.ai_focus)
      
      // æ„å»º Markdown æ ¼å¼çš„æ‘˜è¦
      const summaryMd = `# ${source?.name || 'Unknown Source'} - ${date} æ‘˜è¦

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ
${analysis.summary}

## ğŸ” å…³é”®æ´å¯Ÿ
${analysis.insights.map(insight => `- ${insight}`).join('\n')}

## ğŸ“ˆ è¶‹åŠ¿åˆ†æ
${analysis.trends.map(trend => `- ${trend}`).join('\n')}

## ğŸ’¡ å½±å“è¯„ä¼°
${analysis.impact}

## ğŸ¯ è¡ŒåŠ¨å»ºè®®
${analysis.recommendations.map(rec => `- ${rec}`).join('\n')}

## ğŸ‘¥ å…³é”®å®ä½“
${analysis.keyEntities.map(entity => `- ${entity}`).join('\n')}
`
      
      // æ„å»ºæ´å¯Ÿæ–‡æ¡£
      const insightsMd = `## æ·±åº¦åˆ†æ

### å†…å®¹åˆ†å¸ƒ
- æ€»é¡¹ç›®æ•°: ${items.length}
- ä¸»è¦ä½œè€…: ${this.getTopAuthors(items)}
- çƒ­é—¨æ ‡ç­¾: ${this.getTopTags(items)}

### æ—¶é—´è¶‹åŠ¿
${this.analyzeTimeTrends(items)}

### å†…å®¹è´¨é‡è¯„ä¼°
${this.assessContentQuality(items)}
`
      
      // ä¿å­˜åˆ°æ•°æ®åº“
      const { error: saveError } = await supabase
        .from('daily_digests')
        .upsert({
          source_id: sourceId,
          date,
          summary_md: summaryMd,
          insights_md: insightsMd,
          items: items.map(item => ({
            id: item.id,
            title: item.title,
            url: item.url
          }))
        })
      
      if (saveError) {
        console.error('Failed to save digest:', saveError)
      }
      
      return {
        sourceId,
        date,
        summaryMd,
        insightsMd,
        items
      }
      
    } catch (error) {
      console.error('Daily digest generation error:', error)
      throw error
    }
  }
  
  // è·å–é»˜è®¤åˆ†æç»“æœï¼ˆå½“ AI æœåŠ¡ä¸å¯ç”¨æ—¶ï¼‰
  private static getDefaultAnalysis(items: Array<{
    title: string
    content: string
    author: string
    tags?: string[]
  }>, sourceName: string): AnalysisResult {
    return {
      summary: `ä»Šæ—¥ä» ${sourceName} è·å–äº† ${items.length} æ¡æ–°å†…å®¹ï¼Œæ¶µç›–äº†å¤šä¸ªé‡è¦ä¸»é¢˜ã€‚`,
      insights: [
        'å†…å®¹æ›´æ–°é¢‘ç¹ï¼Œæ˜¾ç¤ºæ´»è·ƒçš„ç¤¾åŒºå‚ä¸',
        'æ¶‰åŠå¤šä¸ªæŠ€æœ¯é¢†åŸŸï¼Œä½“ç°äº†è·¨å­¦ç§‘çš„ç‰¹ç‚¹',
        'è´¨é‡è¾ƒé«˜ï¼ŒåŒ…å«è¯¦ç»†çš„æŠ€æœ¯è®¨è®º'
      ],
      trends: [
        'æŠ€æœ¯å‘å±•æŒç»­åŠ é€Ÿ',
        'å¼€æºé¡¹ç›®æ´»è·ƒåº¦æå‡',
        'è·¨é¢†åŸŸåˆä½œå¢å¤š'
      ],
      impact: 'è¿™äº›å†…å®¹å¯¹ç›¸å…³æŠ€æœ¯é¢†åŸŸçš„å‘å±•å…·æœ‰ç§¯æå½±å“ï¼Œä¸ºå¼€å‘è€…æä¾›äº†å®è´µçš„å‚è€ƒã€‚',
      recommendations: [
        'æŒç»­å…³æ³¨ç›¸å…³æŠ€æœ¯å‘å±•',
        'å‚ä¸ç¤¾åŒºè®¨è®ºå’Œè´¡çŒ®',
        'å°†æ–°æŠ€æœ¯åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­'
      ],
      keyEntities: this.extractKeyEntities(items)
    }
  }
  
  // æå–å…³é”®å®ä½“
  private static extractKeyEntities(items: Array<{
    author: string
    tags?: string[]
  }>): string[] {
    const entities = new Set<string>()
    
    items.forEach(item => {
      // æå–ä½œè€…
      if (item.author) {
        entities.add(item.author)
      }
      
      // ä»æ ‡ç­¾ä¸­æå–å®ä½“
      if (item.tags) {
        item.tags.forEach((tag: string) => {
          if (tag.length > 2) {
            entities.add(tag)
          }
        })
      }
    })
    
    return Array.from(entities).slice(0, 10)
  }
  
  // è·å–ä¸»è¦ä½œè€…
  private static getTopAuthors(items: Array<{
    author: string
  }>): string {
    const authorCount: { [key: string]: number } = {}
    
    items.forEach(item => {
      if (item.author) {
        authorCount[item.author] = (authorCount[item.author] || 0) + 1
      }
    })
    
    const topAuthors = Object.entries(authorCount)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 3)
      .map(([author]) => author)
    
    return topAuthors.join(', ')
  }
  
  // è·å–çƒ­é—¨æ ‡ç­¾
  private static getTopTags(items: Array<{
    tags: string[]
  }>): string {
    const tagCount: { [key: string]: number } = {}
    
    items.forEach(item => {
      if (item.tags) {
        item.tags.forEach((tag: string) => {
          tagCount[tag] = (tagCount[tag] || 0) + 1
        })
      }
    })
    
    const topTags = Object.entries(tagCount)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 5)
      .map(([tag]) => tag)
    
    return topTags.join(', ')
  }
  
  // åˆ†ææ—¶é—´è¶‹åŠ¿
  private static analyzeTimeTrends(items: Array<{
    published_at: string
  }>): string {
    const hourlyCount: { [key: number]: number } = {}
    
    items.forEach(item => {
      const hour = new Date(item.published_at).getHours()
      hourlyCount[hour] = (hourlyCount[hour] || 0) + 1
    })
    
    const peakHour = Object.entries(hourlyCount)
      .sort(([,a], [,b]) => b - a)[0]
    
    return `å†…å®¹å‘å¸ƒé«˜å³°æ—¶é—´: ${peakHour ? `${peakHour[0]}:00 (${peakHour[1]}æ¡)` : 'æ— æ•°æ®'}`
  }
  
  // è¯„ä¼°å†…å®¹è´¨é‡
  private static assessContentQuality(items: Array<{
    content: string
  }>): string {
    const avgLength = items.reduce((sum, item) => 
      sum + (item.content?.length || 0), 0) / items.length
    
    const hasDetailedContent = items.filter(item => 
      item.content && item.content.length > 100).length
    
    return `å¹³å‡å†…å®¹é•¿åº¦: ${Math.round(avgLength)}å­—ç¬¦\nè¯¦ç»†å†…å®¹æ¯”ä¾‹: ${Math.round(hasDetailedContent / items.length * 100)}%`
  }
}
